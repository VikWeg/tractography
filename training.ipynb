{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['PYTHONHASHSEED'] = '0'\n",
    "\n",
    "import random as rn\n",
    "rn.seed(12345)\n",
    "\n",
    "from numpy.random import seed\n",
    "seed(42)\n",
    "\n",
    "from tensorflow.compat.v1 import set_random_seed\n",
    "set_random_seed(42)\n",
    "\n",
    "import nibabel as nib\n",
    "import nipy as ni\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from tensorflow.keras.layers import (Input, Reshape, Dropout, BatchNormalization, Lambda, Dense)\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import cpu_count\n",
    "import glob\n",
    "\n",
    "from GPUtil import getFirstAvailable\n",
    "import datetime\n",
    "import shutil\n",
    "\n",
    "import yaml\n",
    "import csv\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from tensorflow.keras.callbacks import TensorBoard, ModelCheckpoint\n",
    "\n",
    "import tensorflow_probability as tfp\n",
    "\n",
    "tfd = tfp.distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(getFirstAvailable(order=\"load\", maxLoad=10**-6, maxMemory=10**-1)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class input_sequence(tf.keras.utils.Sequence):\n",
    "    def __init__(self, dwi_path, tck_path, batch_size, n_incoming=1, istraining=True):\n",
    "        \"\"\"\"\"\"\n",
    "        self.batch_size = batch_size\n",
    "        self.dwi_path = dwi_path\n",
    "        self.tck_path = tck_path\n",
    "        self.n_incoming = n_incoming\n",
    "        self.istraining = istraining\n",
    "\n",
    "        # TODO: Implement Caching of generated samples\n",
    "        cache_path = (\n",
    "            os.path.basename(self.dwi_path).split(\".\")[0] + \"_\" +\n",
    "            os.path.basename(self.tck_path).split(\".\")[0]\n",
    "        )\n",
    "        \n",
    "        if os.path.exists(cache_path + \".npy\"):\n",
    "            self.inputs = np.load(cache_path + \"_inputs.npy\")\n",
    "            self.outputs = np.load(cache_path + \"_outputs.npy\")\n",
    "            self.n_samples = len(self.inputs)\n",
    "            assert self.inputs.shape[1] / self.n_incoming == 15\n",
    "        else:\n",
    "            dwi_img = ni.load_image(self.dwi_path)\n",
    "            xyz2ijk = lambda r: dwi_img.coordmap.inverse()([r[0], r[1], r[2], 0]).round().astype(int)\n",
    "            dwi = dwi_img.get_data()\n",
    "\n",
    "            tck = nib.streamlines.load(self.tck_path)\n",
    "            fibers = tck.tractogram.streamlines\n",
    "\n",
    "            self.n_fibers = len(fibers)\n",
    "            self.fiber_lengths = [len(f) for f in fibers]\n",
    "            self.n_samples = 0\n",
    "            for f in fibers:\n",
    "                self.n_samples += (len(f) - self.n_incoming - 1)\n",
    "\n",
    "            self.inputs = []\n",
    "            self.outputs = []\n",
    "            for fi, f in enumerate(fibers):\n",
    "                print(\"Finished {:3.0f}%\".format(100*fi/self.n_fibers), end=\"\\r\")\n",
    "                for i in range(self.n_incoming + 1, len(f)):\n",
    "                    vout = f[i, :] - f[i-1, :]\n",
    "                    vout /= np.linalg.norm(vout)\n",
    "                    self.outputs.append(vout.astype(\"float32\"))\n",
    "\n",
    "                    vin = [f[i-j-1, :] - f[i-j-2, :] for j in range(self.n_incoming)]\n",
    "                    # Normalize relative to first vin (does it make sense?)\n",
    "                    vin = [v / np.linalg.norm(vin[0]) for v in vin]\n",
    "                    vin = np.hstack(vin)\n",
    "\n",
    "                    idx = xyz2ijk(f[i-1, :]) # anchor point\n",
    "                    d = dwi[idx[0], idx[1], idx[2], :]\n",
    "\n",
    "                    self.inputs.append(np.hstack([vin, d]).astype(\"float32\"))\n",
    "\n",
    "            # TODO: Randomize samples\n",
    "            \n",
    "            np.save(cache_path + \"_inputs\", self.inputs)\n",
    "            np.save(cache_path + \"_outputs\", self.outputs)\n",
    "\n",
    "        assert self.n_samples == len(self.inputs)\n",
    "        assert self.n_samples == len(self.outputs)\n",
    "\n",
    "        assert self.inputs[0].shape == (3 * self.n_incoming + 15, )\n",
    "        assert self.outputs[0].shape == (3, )\n",
    "\n",
    "        \n",
    "    def __len__(self):\n",
    "        if self.istraining:\n",
    "            return self.n_samples // self.batch_size # drop remainder\n",
    "        else:\n",
    "             return np.ceil(self.n_samples / self.batch_size).astype(int)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        x_batch = np.vstack(self.inputs[idx * self.batch_size:(idx + 1) * self.batch_size])\n",
    "        y_batch = np.vstack(self.outputs[idx * self.batch_size:(idx + 1) * self.batch_size])\n",
    "        \n",
    "        return x_batch, y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = dict(\n",
    "    dwi_path = \"/local/home/vwegmayr/ijcv19/992774_fod.nii.gz\",\n",
    "    tck_path = \"CC.tck\",\n",
    "    batch_size = 128,\n",
    "    epochs = 5,\n",
    "    n_incoming = 3,\n",
    "    save_model = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = Input(shape=(15 + 3 * config[\"n_incoming\"], ),\n",
    "                 name=\"features\")\n",
    "\n",
    "def detrack_fn(features):\n",
    "    \n",
    "    x = Dense(1024, activation=\"relu\")(features)\n",
    "    \n",
    "    x = Dense(1024, activation=\"relu\")(x)\n",
    "    \n",
    "    x = Dense(3, activation=\"linear\")(x)\n",
    "    \n",
    "    return Lambda(lambda x: K.l2_normalize(x, axis=-1), name=\"vout\")(x)\n",
    "\n",
    "model = tf.keras.Model(features, detrack_fn(features), name=\"detrack\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"detrack\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "features (InputLayer)        [(None, 24)]              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1024)              25600     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 3)                 3075      \n",
      "_________________________________________________________________\n",
      "vout (Lambda)                (None, 3)                 0         \n",
      "=================================================================\n",
      "Total params: 1,078,275\n",
      "Trainable params: 1,078,275\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished 100%\r"
     ]
    }
   ],
   "source": [
    "train_seq = input_sequence(config[\"dwi_path\"],\n",
    "                           config[\"tck_path\"],\n",
    "                           config[\"batch_size\"],\n",
    "                           config[\"n_incoming\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_loss(y_true, y_pred):\n",
    "    return -K.mean(K.sum(y_true * y_pred, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models/detrack/2019-10-07-15:45:55\n",
      "\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W1007 15:45:56.082983 139701351245568 deprecation.py:323] From /local/home/vwegmayr/miniconda2/envs/thesis/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8155/8155 [==============================] - 41s 5ms/step - loss: -0.9120\n",
      "Epoch 2/5\n",
      "8155/8155 [==============================] - 41s 5ms/step - loss: -0.9184\n",
      "Epoch 3/5\n",
      "8155/8155 [==============================] - 41s 5ms/step - loss: -0.9205\n",
      "Epoch 4/5\n",
      "8155/8155 [==============================] - 40s 5ms/step - loss: -0.9218\n",
      "Epoch 5/5\n",
      "8155/8155 [==============================] - 41s 5ms/step - loss: -0.9229\n"
     ]
    }
   ],
   "source": [
    "timestamp = datetime.datetime.now().strftime(\"%Y-%m-%d-%H:%M:%S\")\n",
    "model_dir = os.path.join(\"models/detrack\", timestamp)\n",
    "\n",
    "print(model_dir + \"\\n\")\n",
    "\n",
    "try:\n",
    "    no_exception = True\n",
    "    \n",
    "    os.makedirs(model_dir)\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(),\n",
    "        loss=cosine_loss\n",
    "    )\n",
    "    train_history = model.fit_generator(\n",
    "        train_seq,\n",
    "        epochs=config[\"epochs\"],\n",
    "        #validation_data=eval_sequence,\n",
    "        callbacks=[\n",
    "            TensorBoard(log_dir=model_dir, write_graph=False),\n",
    "            #ModelCheckpoint(\"weights.{epoch:02d}-{val_loss:.2f}.hdf5\", save_freq=\"epoch\"),\n",
    "            # EarlyStopping(min_delta=0.05, patience=10, restore_best_weights=True, verbose=1)\n",
    "        ],\n",
    "        #validation_steps=1,\n",
    "        max_queue_size=2*config[\"batch_size\"],\n",
    "        use_multiprocessing=True,\n",
    "        workers=cpu_count()\n",
    "    )\n",
    "except KeyboardInterrupt:\n",
    "    os.rename(model_dir, model_dir + \"_stopped\")\n",
    "    model_dir = model_dir + \"_stopped\"\n",
    "except Exception as e:\n",
    "    shutil.rmtree(model_dir)\n",
    "    no_exception = False\n",
    "    raise e\n",
    "finally:\n",
    "    if no_exception and config[\"save_model\"]:\n",
    "\n",
    "        with open(os.path.join(model_dir, \"config\" + \".yml\"), \"w\") as file:\n",
    "            yaml.dump(config, file, default_flow_style=False)           \n",
    "\n",
    "        model.save(os.path.join(model_dir, \"model\" + \".h5\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
