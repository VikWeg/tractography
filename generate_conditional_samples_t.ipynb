{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['PYTHONHASHSEED'] = '0'\n",
    "import random as rn\n",
    "rn.seed(12345)\n",
    "from numpy.random import seed\n",
    "seed(42)\n",
    "from tensorflow.compat.v1 import set_random_seed\n",
    "set_random_seed(42)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import nibabel as nib\n",
    "import nipy as ni\n",
    "import numpy as np\n",
    "import datetime\n",
    "import shutil\n",
    "import yaml\n",
    "import csv\n",
    "import json\n",
    "\n",
    "from hashlib import md5\n",
    "from scipy.interpolate import RegularGridInterpolator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_samples(config):\n",
    "    \"\"\"\"\"\"\n",
    "    if config[\"block_size\"] % 2 == 0:\n",
    "        raise ValueError(\"block_size must be an odd number (1, 3, 5,...)\")\n",
    "    \n",
    "    subject_dir = os.path.join(\"subjects\", config[\"subject\"])\n",
    "    \n",
    "    trk_path = os.path.join(subject_dir, config[\"trk_path\"])\n",
    "    dwi_path = os.path.join(subject_dir, config[\"dwi_path\"])\n",
    "    \n",
    "    hasher = md5()\n",
    "    for v in config.values():\n",
    "        hasher.update(str(v).encode())\n",
    "    \n",
    "    save_dir = os.path.join(subject_dir, \"samples\", hasher.hexdigest())\n",
    "    if os.path.exists(save_dir):\n",
    "        print(\"Samples with this config have been created already:\\n{}\".format(save_dir))\n",
    "        return None, None\n",
    "    \n",
    "    tracts = nib.streamlines.load(trk_path).tractogram\n",
    "    assert tracts.data_per_point is not None\n",
    "    assert \"t\" in tracts.data_per_point\n",
    "    \n",
    "    dwi_img = ni.load_image(dwi_path)\n",
    "    xyz2ijk = lambda r: dwi_img.coordmap.inverse()([r[0], r[1], r[2], 0])[:3]\n",
    "    dwi = dwi_img.get_data()\n",
    "\n",
    "    n_fibers = len(tracts)\n",
    "    fiber_lengths = [len(f) for f in tracts]\n",
    "    n_samples = np.sum(fiber_lengths) - 2 * n_fibers\n",
    "    if config[\"reverse_samples\"]:\n",
    "        n_samples *= 2 \n",
    "    n_samples = min(n_samples, config[\"max_n_samples\"])\n",
    "    \n",
    "    np.random.seed(42)\n",
    "    perm = np.random.permutation(len(tracts))\n",
    "    tracts = tracts[perm]\n",
    "    \n",
    "    inputs = []\n",
    "    outputs = []\n",
    "    done=False\n",
    "    for fi, f in enumerate(tracts):  \n",
    "        for i, r in enumerate(f.streamline[1:-1]): # Exclude end points for conditional model\n",
    "            \n",
    "            try:\n",
    "                idx = xyz2ijk(r) # anchor idx\n",
    "                IDX = np.round(idx).astype(int)\n",
    "                \n",
    "                values = np.zeros([3, 3, 3,\n",
    "                                   config[\"block_size\"], config[\"block_size\"], config[\"block_size\"],\n",
    "                                   dwi.shape[-1]])\n",
    "                \n",
    "                for x in range(config[\"block_size\"]):\n",
    "                    for y in range(config[\"block_size\"]):\n",
    "                        for z in range(config[\"block_size\"]):\n",
    "                            values[x, y, z,:] = dwi[\n",
    "                                IDX[0] + x - 2 * (config[\"block_size\"] // 2) : IDX[0] + x + 1,\n",
    "                                IDX[1] + y - 2 * (config[\"block_size\"] // 2) : IDX[1] + y + 1,\n",
    "                                IDX[2] + z - 2 * (config[\"block_size\"] // 2) : IDX[2] + z + 1,\n",
    "                                :]\n",
    "                fn = RegularGridInterpolator(([-1,0,1],[-1,0,1],[-1,0,1]), values)\n",
    "                \n",
    "                d = fn([idx[0]-IDX[0], idx[1]-IDX[1], idx[2]-IDX[2]])[0]\n",
    "                d = d.flatten() # to get back the spatial order: reshape(bs, bs, bs, dwi.shape[-1])\n",
    "                \n",
    "            except IndexError:\n",
    "                n_samples -= (2 if config[\"reverse_samples\"] else 1)\n",
    "                print(\"Index error at r={}, idx={}, fiber_idx={}\\n\".format(r,idx,perm[fi]) +\n",
    "                      \"Maybe wrong reference frame, or resampling failed.\"\n",
    "                     )\n",
    "                continue\n",
    "                \n",
    "            vout = f.data_for_points[\"t\"][i+1].astype(\"float32\")\n",
    "            vin = f.data_for_points[\"t\"][i].astype(\"float32\")\n",
    "\n",
    "            outputs.append(vout)\n",
    "            inputs.append(np.hstack([vin, d]).astype(\"float32\"))\n",
    "\n",
    "            if config[\"reverse_samples\"]:\n",
    "                inputs.append(np.hstack([-vout, d]).astype(\"float32\"))\n",
    "                outputs.append(-vin)\n",
    "\n",
    "            if len(inputs) == n_samples:\n",
    "                done = True\n",
    "                break\n",
    "\n",
    "        print(\"Finished {:3.0f}%\".format(100*len(inputs)/n_samples), end=\"\\r\")\n",
    "\n",
    "        if done:\n",
    "            break\n",
    "\n",
    "    assert n_samples == len(inputs)\n",
    "    assert n_samples == len(outputs)\n",
    "    assert inputs[0].shape == (3 + dwi_img.shape[-1] * config[\"block_size\"]**3, )\n",
    "    assert outputs[0].shape == (3, )\n",
    "\n",
    "    os.makedirs(save_dir)\n",
    "\n",
    "    save_path = os.path.join(save_dir, \"samples.npz\")\n",
    "    \n",
    "    print(\"Saving {}\".format(save_path))\n",
    "    np.savez_compressed(save_path, inputs=inputs, outputs=outputs)\n",
    "    \n",
    "    config[\"n_samples\"] = int(n_samples)\n",
    "    config_path = os.path.join(save_dir, \"config\" + \".yml\")\n",
    "    print(\"Saving {}\".format(config_path))\n",
    "    with open(config_path, \"w\") as file:\n",
    "            yaml.dump(config, file, default_flow_style=False)\n",
    "            \n",
    "    return inputs, outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = dict(\n",
    "    subject=\"992774\",\n",
    "    sample_type=\"conditional_t\",\n",
    "    dwi_path = \"fod.nii.gz\",\n",
    "    trk_path = \"resampled_fibers/merged_w1_smooth=5_npts=auto.trk\",\n",
    "    block_size = 3,\n",
    "    reverse_samples = True,\n",
    "    max_n_samples = 1000,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples with this config have been created already:\n",
      "subjects/992774/samples/40b9069c14f30aefc8fc14e9143964b5\n"
     ]
    }
   ],
   "source": [
    "inputs, outputs = create_samples(config)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
