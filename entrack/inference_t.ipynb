{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['PYTHONHASHSEED'] = '0'\n",
    "import random as rn\n",
    "rn.seed(12345)\n",
    "from numpy.random import seed\n",
    "seed(42)\n",
    "from tensorflow.compat.v1 import set_random_seed\n",
    "set_random_seed(42)\n",
    "\n",
    "import yaml\n",
    "import datetime\n",
    "\n",
    "import nipy as ni\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.models import load_model\n",
    "from GPUtil import getFirstAvailable\n",
    "from tensorflow.keras import backend as K\n",
    "from nibabel.streamlines.tck import TckFile\n",
    "from nibabel.streamlines.array_sequence import ArraySequence, concatenate\n",
    "from nibabel.streamlines.tractogram import Tractogram\n",
    "from hashlib import md5\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "import tensorflow_probability as tfp\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(config):\n",
    "    \"\"\"\n",
    "    seeds: [[x1,y1,z1],...,[xn,yn,zn]]\n",
    "    \"\"\"\n",
    "    # Load Data\n",
    "    \n",
    "    subject_dir = os.path.join(\"..\", \"subjects\", config[\"subject\"])\n",
    "    \n",
    "    dwi_path = os.path.join(subject_dir, config[\"dwi_path\"])\n",
    "    model_path = os.path.join(config[\"model_dir\"], \"model.h5\")\n",
    "    \n",
    "    hasher = md5()\n",
    "    for v in config.values():\n",
    "        hasher.update(str(v).encode())\n",
    "    \n",
    "    save_dir = os.path.join(subject_dir, \"predicted_fibers\", hasher.hexdigest())\n",
    "    if os.path.exists(save_dir):\n",
    "        print(\"Predictions with this config have been created already:\\n{}\".format(save_dir))\n",
    "        return\n",
    "    \n",
    "    dwi_img = ni.load_image(dwi_path)\n",
    "    dwi = dwi_img.get_data()\n",
    "    \n",
    "    def ijk2xyz(indices):\n",
    "        indices = np.hstack([indices, np.zeros((len(indices),1))])\n",
    "        return dwi_img.coordmap(indices)[:, :3]\n",
    "    \n",
    "    def xyz2ijk(coords):\n",
    "        coords = np.hstack([coords, np.zeros((len(coords),1))])\n",
    "        ijk = dwi_img.coordmap.inverse()(coords).round().astype(int)[:, :3]\n",
    "        return np.clip(ijk,\n",
    "                       np.tile([0,0,0], (len(ijk), 1)),\n",
    "                       np.tile(dwi.shape[:3], (len(ijk), 1)) - 1\n",
    "        )\n",
    "    \n",
    "    # Define Fiber Termination\n",
    "    \n",
    "    class Terminator(object):\n",
    "        def __init__(self):\n",
    "            if \".nii\" in config[\"terminator\"][0]:\n",
    "                scalar_img = ni.load_image(os.path.join(subject_dir, config[\"terminator\"][0]))\n",
    "                self.scalar = scalar_img.get_data()\n",
    "            else:\n",
    "                raise NotImplementedError # TODO: Implement termination model\n",
    "            self.threshold = config[\"terminator\"][1]\n",
    "        def __call__(self, ijk):\n",
    "            if hasattr(self, \"scalar\"):\n",
    "                return np.where(self.scalar[ijk[:,0],ijk[:,1],ijk[:,2]] < self.threshold)[0]\n",
    "            else:\n",
    "                raise NotImplementedError\n",
    "\n",
    "    terminator = Terminator()\n",
    "    \n",
    "    seeds = np.load(os.path.join(subject_dir, config[\"seeds\"]))\n",
    "    # Duplicate seeds for positive and negative starting direction\n",
    "    seeds = np.vstack([seeds, seeds])\n",
    "    \n",
    "    # Define Prior for First Fiber Direction\n",
    "    \n",
    "    class Prior(object):\n",
    "        def __init__(self):\n",
    "            if \".nii\" in config[\"prior\"]:\n",
    "                peak_img = ni.load_image(os.path.join(subject_dir, config[\"prior\"]))\n",
    "                self.peak = peak_img.get_data()\n",
    "            elif \".h5\" in config:\n",
    "                raise NotImplementedError # TODO: Implement prior model\n",
    "                \n",
    "        def __call__(self, xyz):\n",
    "            if hasattr(self, \"peak\"):\n",
    "                ijk = xyz2ijk(xyz)\n",
    "                # Assuming that seeds have been duplicated\n",
    "                return self.peak[ijk[:,0],ijk[:,1],ijk[:,2]] * np.repeat([[1],[-1]], len(ijk)/2, axis=0)\n",
    "            elif hasattr(self, \"model\"):\n",
    "                raise NotImplementedError # TODO: Implement prior model\n",
    "        \n",
    "    prior = Prior()\n",
    "    \n",
    "    # Load Model\n",
    "    \n",
    "    def negative_log_likelihood(observed_y, predicted_distribution):\n",
    "        return -K.mean(predicted_distribution.log_prob(observed_y))\n",
    "    \n",
    "    model = load_model(model_path,\n",
    "                       custom_objects={\"negative_log_likelihood\": negative_log_likelihood,\n",
    "                                       \"DistributionLambda\": tfp.layers.DistributionLambda})\n",
    "    \n",
    "    # Begin Iterative Prediction\n",
    "    \n",
    "    ijk = xyz2ijk(seeds)\n",
    "    xyz = seeds.reshape(-1, 1, 3) # [fiber, pt, coo]\n",
    "    fiber_idx = np.hstack([np.arange(len(seeds)//2), np.arange(len(seeds)//2)])\n",
    "    fibers = [[] for _ in range(len(seeds)//2)]\n",
    "    for i in range(config[\"max_steps\"]):\n",
    "        \n",
    "        d = dwi[ijk[:,0], ijk[:,1], ijk[:,2], :]\n",
    "        \n",
    "        if i == 0:\n",
    "            vin = prior(xyz[:,0,:])\n",
    "        else:\n",
    "            vin = vout.copy()\n",
    "        \n",
    "        if config[\"predict_fn\"] == \"mean\":\n",
    "            vout = model(np.hstack([vin,d])).mean().numpy()\n",
    "            vout = normalize(vout) # Careful, the FvM mean is not a unit vector!\n",
    "        else:\n",
    "            vout = model(np.hstack([vin,d])).sample().numpy()\n",
    "        \n",
    "        rout = (xyz[:,-1,:] + config[\"step_size\"] * vout).reshape(-1, 1, 3)\n",
    "        \n",
    "        xyz = np.concatenate([xyz, rout], axis=1)\n",
    "        \n",
    "        ijk = xyz2ijk(xyz[:,-1,:])\n",
    "        \n",
    "        terminal_indices = terminator(ijk)\n",
    "\n",
    "        for idx in terminal_indices:\n",
    "            gidx = fiber_idx[idx]\n",
    "            # Other end not yet added\n",
    "            if not fibers[gidx]:\n",
    "                fibers[gidx].append(xyz[idx])\n",
    "            # Other end already added\n",
    "            else:\n",
    "                this_end = xyz[idx]\n",
    "                other_end = fibers[gidx][0]\n",
    "                merged_fiber = np.vstack([np.flip(this_end[1:], axis=0), other_end]) # stitch ends together\n",
    "                fibers[gidx] = [merged_fiber]\n",
    "                \n",
    "        xyz = np.delete(xyz, terminal_indices, axis=0)\n",
    "        vout = np.delete(vout, terminal_indices, axis=0)\n",
    "        fiber_idx = np.delete(fiber_idx, terminal_indices)\n",
    "        \n",
    "        ijk = xyz2ijk(xyz[:,-1,:])\n",
    "        \n",
    "        print(\"Step {:4d}/{}, finished {:5d}/{:5d} ({:3.0f}%) of all seeds.\".format(\n",
    "            (i+1), config[\"max_steps\"], len(seeds)-len(fiber_idx), len(seeds),\n",
    "            100*(1-len(fiber_idx)/len(seeds))), end=\"\\r\")\n",
    "\n",
    "        if len(fiber_idx) == 0:\n",
    "            break\n",
    "    \n",
    "    # Include unfinished fibers:\n",
    "    \n",
    "    for idx, gidx in enumerate(fiber_idx):\n",
    "        if not fibers[gidx]:\n",
    "            fibers[gidx].append(xyz[idx])\n",
    "        else:\n",
    "            this_end = xyz[idx]\n",
    "            other_end = fibers[gidx][0]\n",
    "            merged_fiber = np.vstack([np.flip(this_end[1:], axis=0), other_end])\n",
    "            fibers[gidx] = [merged_fiber]\n",
    "    \n",
    "    # Save Result\n",
    "    \n",
    "    fibers = [f[0] for f in fibers]\n",
    "    \n",
    "    tractogram = Tractogram(\n",
    "        streamlines=ArraySequence(fibers),\n",
    "        affine_to_rasmm=np.eye(4)\n",
    "    )\n",
    "    \n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "    fiber_path = os.path.join(save_dir, \"fibers.trk\")\n",
    "    print(\"\\nSaving {}\".format(fiber_path))\n",
    "    nib.streamlines.save(tractogram, fiber_path)\n",
    "\n",
    "    config_path = os.path.join(save_dir, \"config.yml\")\n",
    "    print(\"Saving {}\".format(config_path))\n",
    "    with open(config_path, \"w\") as file:\n",
    "        yaml.dump(config, file, default_flow_style=False) \n",
    "    \n",
    "    return tractogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(getFirstAvailable(order=\"load\", maxLoad=10**-6, maxMemory=10**-1)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = dict(\n",
    "    subject=\"992774\",\n",
    "    model_dir=\"../models/entrack_conditional/8d5593b08d4548286cc8564373e82e11\",\n",
    "    dwi_path=\"fod.nii.gz\",\n",
    "    prior=\"peak.nii.gz\",\n",
    "    seeds=\"seeds/bcc2e734e49c597e25ece8a3d499d060/seeds.npy\",\n",
    "    terminator=[\"fa.nii.gz\", 0.21],\n",
    "    predict_fn=\"mean\",\n",
    "    step_size=0.2,\n",
    "    max_steps=500\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step  500/500, finished 360701/364160 ( 99%) of all seeds.\n",
      "Saving ../subjects/992774/predicted_fibers/f13ac4341f570118dd1de8dd3b424303/fibers.trk\n",
      "Saving ../subjects/992774/predicted_fibers/f13ac4341f570118dd1de8dd3b424303/config.yml\n"
     ]
    }
   ],
   "source": [
    "tractogram = predict(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
