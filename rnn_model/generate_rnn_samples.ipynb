{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['PYTHONHASHSEED'] = '0'\n",
    "import random as rn\n",
    "rn.seed(12345)\n",
    "from numpy.random import seed\n",
    "seed(42)\n",
    "from tensorflow.compat.v1 import set_random_seed\n",
    "set_random_seed(42)\n",
    "\n",
    "import nibabel as nib\n",
    "import nipy as ni\n",
    "import numpy as np\n",
    "import datetime\n",
    "import shutil\n",
    "import yaml\n",
    "import csv\n",
    "import json\n",
    "import warnings\n",
    "import time\n",
    "\n",
    "from hashlib import md5\n",
    "from scipy.interpolate import RegularGridInterpolator\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_samples(config):\n",
    "    \"\"\"\"\"\"\n",
    "    subject_dir = os.path.join(\"../subjects\", config[\"subject\"])\n",
    "    \n",
    "    trk_path = os.path.join(subject_dir, config[\"trk_path\"])\n",
    "    dwi_path = os.path.join(subject_dir, config[\"dwi_path\"])\n",
    "    \n",
    "    hasher = md5()\n",
    "    hasher.update(config[\"sample_type\"].encode())\n",
    "    hasher.update(open(dwi_path, \"rb\").read())\n",
    "    hasher.update(open(trk_path, \"rb\").read())\n",
    "    hasher.update(str(config[\"reverse_samples\"]).encode())\n",
    "    hasher.update(str(config[\"max_n_samples\"]).encode())\n",
    "    \n",
    "    save_dir = os.path.join(subject_dir, \"samples\", hasher.hexdigest())\n",
    "    if os.path.exists(save_dir):\n",
    "        print(\"Samples with this config have been created already:\\n{}\".format(save_dir))\n",
    "        return\n",
    "    \n",
    "    tracts = nib.streamlines.load(trk_path).tractogram\n",
    "    assert tracts.data_per_point is not None\n",
    "    assert \"t\" in tracts.data_per_point\n",
    "    \n",
    "    dwi_img = ni.load_image(dwi_path)\n",
    "    xyz2ijk = lambda r: dwi_img.coordmap.inverse()([r[0], r[1], r[2], 0])[:3]\n",
    "    dwi = dwi_img.get_data()\n",
    "\n",
    "    n_fibers = len(tracts)\n",
    "    fiber_lengths = [len(f) for f in tracts]\n",
    "    n_samples = np.sum(fiber_lengths) - 2 * n_fibers\n",
    "    if config[\"reverse_samples\"]:\n",
    "        n_samples *= 2 \n",
    "    n_samples = min(n_samples, config[\"max_n_samples\"])\n",
    "    \n",
    "    np.random.seed(42)\n",
    "    perm = np.random.permutation(len(tracts))\n",
    "    tracts = tracts[perm]\n",
    "    \n",
    "    inputs = []\n",
    "    outputs = []\n",
    "    total_samples = 0\n",
    "    done=False\n",
    "    for fi, f in enumerate(tracts):\n",
    "        start = time.time()\n",
    "        fib_len = (len(f)-2) * 2 if config[\"reverse_samples\"] else len(f)-2\n",
    "        split_num = fib_len // config['seq_len']\n",
    "        max_samples = split_num // 2 if config[\"reverse_samples\"] else split_num\n",
    "        n_samples = n_samples - (fib_len % config['seq_len'])\n",
    "        \n",
    "        tract_input = np.zeros((split_num, config['seq_len'], 408))\n",
    "        tract_output = np.zeros((split_num, config['seq_len'], 3))\n",
    "        for i, r in enumerate(f.streamline[1:-1]): # Exclude end points        \n",
    "            try:\n",
    "                idx = xyz2ijk(r) # anchor idx\n",
    "                IDX = np.round(idx).astype(int)\n",
    "                \n",
    "                values = np.zeros([3, 3, 3,\n",
    "                                   config[\"block_size\"], config[\"block_size\"], config[\"block_size\"],\n",
    "                                   dwi.shape[-1]])\n",
    "                \n",
    "                for x in range(config[\"block_size\"]):\n",
    "                    for y in range(config[\"block_size\"]):\n",
    "                        for z in range(config[\"block_size\"]):\n",
    "                            values[x, y, z,:] = dwi[\n",
    "                                IDX[0] + x - 2 * (config[\"block_size\"] // 2) : IDX[0] + x + 1,\n",
    "                                IDX[1] + y - 2 * (config[\"block_size\"] // 2) : IDX[1] + y + 1,\n",
    "                                IDX[2] + z - 2 * (config[\"block_size\"] // 2) : IDX[2] + z + 1,\n",
    "                                :]\n",
    "                fn = RegularGridInterpolator(([-1,0,1],[-1,0,1],[-1,0,1]), values)\n",
    "                \n",
    "                d = fn([idx[0]-IDX[0], idx[1]-IDX[1], idx[2]-IDX[2]])[0]\n",
    "                d = d.flatten() # to get back the spatial order: reshape(bs, bs, bs, dwi.shape[-1])\n",
    "                \n",
    "            except IndexError:\n",
    "                n_samples -= (2 if config[\"reverse_samples\"] else 1)\n",
    "                print(\"Index error at r={}, idx={}, fiber_idx={}\\n\".format(r,idx,perm[fi]) +\n",
    "                      \"Maybe wrong reference frame, or resampling failed.\"\n",
    "                     )\n",
    "                continue\n",
    "                \n",
    "            vout = f.data_for_points[\"t\"][i+1].astype(\"float32\")\n",
    "            vin = f.data_for_points[\"t\"][i].astype(\"float32\")\n",
    "\n",
    "            i_pos = i // config['seq_len']\n",
    "            j_pos = i % config['seq_len']\n",
    "            \n",
    "            if (i_pos == max_samples):\n",
    "                break\n",
    "            tract_input[i_pos, j_pos,...] = np.hstack([vin, d]).astype(\"float32\")\n",
    "            tract_output[i_pos, j_pos ,...] = vout\n",
    "            total_samples = total_samples + 1\n",
    "\n",
    "            if config[\"reverse_samples\"]:\n",
    "                i_pos = (split_num // 2) + (i // config['seq_len'])\n",
    "                j_pos = i % config['seq_len']\n",
    "                \n",
    "                tract_input[i_pos, j_pos,...] = np.hstack([-vout, d]).astype(\"float32\")\n",
    "                tract_output[i_pos, j_pos ,...] = -vin\n",
    "                total_samples = total_samples + 1\n",
    "      \n",
    "            if total_samples == n_samples:\n",
    "                done = True\n",
    "                break\n",
    "                \n",
    "        \n",
    "        inputs.append(tract_input)\n",
    "        outputs.append(tract_output)\n",
    "        print(\"Finished {:3.0f}% in {}\".format(100*total_samples/n_samples, time.time() - start), end=\"\\r\")\n",
    "        \n",
    "        if done:\n",
    "            break         \n",
    "\n",
    "    os.makedirs(save_dir)\n",
    "\n",
    "    inputs = np.concatenate(inputs, axis=0)\n",
    "    outputs = np.concatenate(outputs, axis=0)\n",
    "    save_path = os.path.join(save_dir, \"samples.npz\")\n",
    "    \n",
    "    print(\"Saving {}\".format(save_path))\n",
    "    np.savez_compressed(save_path, inputs=inputs, outputs=outputs)\n",
    "    \n",
    "    config[\"n_samples\"] = int(n_samples)\n",
    "    config_path = os.path.join(save_dir, \"config\" + \".yml\")\n",
    "    print(\"Saving {}\".format(config_path))\n",
    "    with open(config_path, \"w\") as file:\n",
    "            yaml.dump(config, file, default_flow_style=False)\n",
    "            \n",
    "    return inputs, outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = dict(\n",
    "    subject=\"992774\",\n",
    "    sample_type=\"rnn\",\n",
    "    seq_len=3,\n",
    "    dwi_path = \"fod.nii.gz\",\n",
    "    trk_path = \"resampled_fibers/merged_w20_smooth=6_npts=auto.trk\",\n",
    "    reverse_samples = True,\n",
    "    block_size = 3,\n",
    "    max_n_samples = 1000,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving ../subjects/992774/samples/e09d97e5447d8a380d51369e4e4f692f/samples.npz\n",
      "Saving ../subjects/992774/samples/e09d97e5447d8a380d51369e4e4f692f/config.yml\n"
     ]
    }
   ],
   "source": [
    "inputs, outputs = create_samples(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(346, 3, 3)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
