import os
import argparse
import datetime
import shutil
import yaml
import importlib
import logging

import tensorflow as tf
import numpy as np
from tensorflow.keras import backend as K

from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau
from multiprocessing import cpu_count
from GPUtil import getFirstAvailable

from models import MODELS
from utils import summaries, Temperature
from utils import callbacks as cb


def train(model_name,
          train_path,
          eval_path,
          batch_size,
          epochs,
          learning_rate,
          optimizer,
          suffix,
          loss_weight,
          temperature,
          out_dir):


    timestamp = datetime.datetime.now().strftime("%Y-%m-%d-%H:%M:%S")
    out_dir = os.path.join(out_dir, model_name, suffix, timestamp)
    os.makedirs(out_dir, exist_ok=True)

    # Load Model ###############################################################

    input_shape = tuple(np.load(train_path, allow_pickle=True)["input_shape"])

    if "Entrack" in model_name:
        temp = Temperature(temperature)
        model = MODELS[model_name](input_shape, temp)
        train_seq = model.get_sequence(train_path, batch_size)
        callbacks = [
            cb.RunningWindowLogger(
            metrics=["kappa_mean", "fvm_mean_neg_dot_prod"],
            window_size=len(train_seq)//20,
            log_std=True),
            cb.AutomaticTemperatureSchedule(
            T_start=temp,
            T_stop=0.005,
            decay=0.99,
            tol=0.01,
            min_lr=0.0001,
            n_checkpoints=10,
            out_dir=out_dir
            ),
        ]
    elif "RNN" in model_name:
        model = MODELS[model_name](input_shape, batch_size=batch_size)
        train_seq = model.get_sequence(train_path, batch_size)
        callbacks = [cb.RNNResetCallBack(train_seq.reset_batches)]
    else:
        model = MODELS[model_name](input_shape, loss_weight=loss_weight)
        train_seq = model.get_sequence(train_path, batch_size)
        callbacks = []

    # Run Training #############################################################
    
    if eval_path is not None:
        eval_seq = model.get_sequence(eval_path, batch_size, istraining=False)
    else:
        eval_seq = None

    # Put Tensorboard callback at the end to catch logs from previous callbacks
    if hasattr(model, "summaries"):
        callbacks.append(
            getattr(summaries, model.summaries)(
            eval_seq=eval_seq,
            activations_freq=len(train_seq)//3, # //k times per epoch
            log_dir=out_dir,
            write_graph=False,
            update_freq=batch_size * (len(train_seq)//100), # //k times per epoch
            profile_batch=0
            )
        )
    try:
        print("\nStart training...\n")

        optimizer=getattr(tf.keras.optimizers, optimizer)(learning_rate,
            clipnorm=10.)

        config=dict(
            model_name=model_name,
            train_path=train_path,
            eval_path=str(eval_path),
            batch_size=str(batch_size),
            epochs=str(epochs),
            learning_rate=str(learning_rate),
            optimizer=optimizer._keras_api_names[0])
        if "Hybrid" in model_name:
            config["loss_weight"] = str(loss_weight)
        if "Entrack" in model_name:
            config["temperature"] = str(temperature)

        config_path = os.path.join(out_dir, "config" + ".yml")
        print("\nSaving {}".format(config_path))
        with open(config_path, "w") as file:
            yaml.dump(config, file, default_flow_style=False)

        no_exception = True

        model.compile(optimizer)

        do_shuffle = False if "RNN" in model_name else True
        train_history = model.keras.fit_generator(
            train_seq,
            epochs=epochs,
            validation_data=eval_seq,
            callbacks=callbacks,
            max_queue_size=4 * batch_size,
            use_multiprocessing=True,
            shuffle=do_shuffle,
            workers=cpu_count()
        )
    except Exception as e:
        shutil.rmtree(out_dir)
        no_exception = False
        raise e
    finally:
        if no_exception:
            model_path = os.path.join(out_dir, "final_model.h5")
            print("\nSaving {}".format(model_path))
            model.keras.save(model_path)

    return model


if __name__ == '__main__':

    parser = argparse.ArgumentParser(description="Train a fiber tracking model")

    parser.add_argument("model_name", type=str, choices=list(MODELS.keys()),
        help="Name of model to be trained.")

    parser.add_argument("train_path", type=str,
        help="Path to training samples file generated by "
        "`generate_conditional_samples.py` are saved")

    parser.add_argument("--eval", type=str, default=None, dest="eval_path",
        help="Path to evaluation samples file generated by "
        "`generate_conditional_samples.py` are saved")

    parser.add_argument("--batch_size", type=int, default=256,
                        help="batch size")

    parser.add_argument("--epochs", type=int, default=10,
                        help="Number of training epochs")

    parser.add_argument("--lr", type=float, default=0.001, dest="learning_rate",
                        help="Learning rate.")

    parser.add_argument("--opt", type=str, default="Adam", dest="optimizer",
                        help="Optimizer name.")

    parser.add_argument("--suffix", type=str, default="",
        help="Model subfolder to distinguish e.g. conditional and prior models.")

    parser.add_argument("--out", type=str, default='models', dest="out_dir",
        help="Directory to save the training results")

    parser.add_argument("--lw", type=float, default=None, dest="loss_weight",
        help="Total weight of terminal loss, must be set for hybrid models.")

    parser.add_argument("--T", type=float, default=None, dest="temperature",
        help="Temperature, must be set for Entrack models.")

    args = parser.parse_args()

    if "Hybrid" in args.model_name:
        if args.loss_weight is None:
            parser.error("Hybrid models require loss_weight (--lw).")

    if "Entrack" in args.model_name:
        if args.temperature is None:
            parser.error("Entrack models require temperature (--T).")

    os.environ['PYTHONHASHSEED'] = '0'
    tf.compat.v1.set_random_seed(3)
    np.random.seed(3)

    os.environ['TF_CPP_MIN_LOG_LEVEL'] = "2"  # ERROR
    logging.getLogger('tensorflow').setLevel(logging.ERROR)

    try:
        os.environ["CUDA_VISIBLE_DEVICES"] = str(getFirstAvailable(order="load",
            maxLoad=10 ** -6, maxMemory=10 ** -1)[0])
    except Exception as e:
        print(str(e))

    train(args.model_name,
          args.train_path,
          args.eval_path,
          args.batch_size,
          args.epochs,
          args.learning_rate,
          args.optimizer,
          args.suffix,
          args.loss_weight,
          args.temperature,
          args.out_dir)