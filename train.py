import os
import argparse
import datetime
import shutil
import yaml

import tensorflow as tf
import numpy as np

from tensorflow.keras.callbacks import TensorBoard, ModelCheckpoint
from multiprocessing import cpu_count
from GPUtil import getFirstAvailable

from models import MODELS

class ConditionalSamples(tf.keras.utils.Sequence):
    def __init__(self,
                 sample_path,
                 batch_size=256,
                 istraining=True,
                 max_n_samples=np.inf):
        """"""
        self.batch_size = batch_size
        self.istraining = istraining

        samples = np.load(sample_path)

        self.inputs = samples["inputs"]
        self.outputs = samples["outputs"]

        assert len(self.inputs) == len(self.outputs)

        self.inputs = self.inputs[:min(max_n_samples, len(self.inputs))]
        self.outputs = self.outputs[:min(max_n_samples, len(self.outputs))]

        self.n_samples = len(self.inputs)

        assert self.n_samples > 0

    def __len__(self):
        if self.istraining:
            return self.n_samples // self.batch_size  # drop remainder
        else:
            return np.ceil(self.n_samples / self.batch_size).astype(int)

    def __getitem__(self, idx):
        x_batch = np.vstack(
            self.inputs[idx * self.batch_size:(idx + 1) * self.batch_size])
        y_batch = np.vstack(
            self.outputs[idx * self.batch_size:(idx + 1) * self.batch_size])

        return x_batch, y_batch


def train(model_name,
          train_path,
          eval_path,
          max_n_samples,
          batch_size,
          epochs,
          learning_rate,
          optimizer,
          out_dir):

    input_shape = tuple(np.load(train_path)["input_shape"])
    model = MODELS[model_name](input_shape)
    model.keras.summary()

    # Run Training

    timestamp = datetime.datetime.now().strftime("%Y-%m-%d-%H:%M:%S")
    out_dir = os.path.join(out_dir, model_name, timestamp)
    os.makedirs(out_dir, exist_ok=True)

    train_seq = ConditionalSamples(
        train_path,
        batch_size,
        max_n_samples=max_n_samples
    )
    callbacks = [
        TensorBoard(log_dir=out_dir,
                    write_graph=False,
                    update_freq=5 * batch_size,
                    profile_batch=0)
    ]

    if eval_path is not None:
        eval_seq = ConditionalSamples(eval_path, istraining=False)
        callbacks.append(
            ModelCheckpoint(
                os.path.join(out_dir, "model.{epoch:02d}-{val_loss:.2f}.h5"),
                save_best_only=True,
                save_weights_only=False)
        )
    else:
        eval_seq = None

    try:
        no_exception = True

        optimizer=getattr(tf.keras.optimizers, optimizer)(learning_rate)
        model.compile(optimizer)

        train_history = model.keras.fit_generator(
            train_seq,
            epochs=epochs,
            validation_data=eval_seq,
            callbacks=callbacks,
            max_queue_size=2 * batch_size,
            use_multiprocessing=True,
            workers=cpu_count()
        )
    except KeyboardInterrupt:
        os.rename(out_dir, out_dir + "_stopped")
        out_dir = out_dir + "_stopped"
    except Exception as e:
        shutil.rmtree(out_dir)
        no_exception = False
        raise e
    finally:
        if no_exception:
            config=dict(
                model_name=model_name,
                train_path=train_path,
                eval_path=str(eval_path),
                max_n_samples=str(max_n_samples),
                batch_size=str(batch_size),
                epochs=str(epochs),
                learning_rate=str(learning_rate),
                optimizer=optimizer._keras_api_names[0])
            config_path = os.path.join(out_dir, "config" + ".yml")
            print("Saving {}".format(config_path))
            with open(config_path, "w") as file:
                yaml.dump(config, file, default_flow_style=False)

            if eval_path is None:
                model_path = os.path.join(out_dir, "model.h5")
                print("Saving {}".format(model_path))
                model.keras.save(model_path)

    return model


if __name__ == '__main__':

    os.environ['PYTHONHASHSEED'] = '0'
    tf.compat.v1.set_random_seed(3)
    np.random.seed(3)

    try:
        os.environ["CUDA_VISIBLE_DEVICES"] = str(getFirstAvailable(
            order="load", maxLoad=10 ** -6, maxMemory=10 ** -1)[0])
    except Exception as e:
        print(str(e))

    parser = argparse.ArgumentParser(description="Train a fiber tracking model")

    parser.add_argument("model_name", type=str, choices=list(MODELS.keys()),
        help="Name of model to be trained.")

    parser.add_argument("train_path", type=str,
        help="Path to training samples file generated by `generate_conditional_samples.py` are saved")

    parser.add_argument("--eval", type=str, default=None, dest="eval_path",
        help="Path to evaluation samples file generated by `generate_conditional_samples.py` are saved")

    parser.add_argument("--max_n_samples", type=int, default=np.inf,
        help="Maximum number of samples to be used for both training and evaluation")

    parser.add_argument("--batch_size", type=int, default=256,
                        help="batch size")

    parser.add_argument("--epochs", type=int, default=10,
                        help="Number of training epochs")

    parser.add_argument("--lr", type=float, default=0.001, dest="learning_rate",
                        help="Learning rate.")

    parser.add_argument("--opt", type=str, default="Adam", dest="optimizer",
                        help="Optimizer name.")

    parser.add_argument("--out", type=str, default='models', dest="out_dir",
        help="Directory to save the training results")

    args = parser.parse_args()

    train(args.model_name,
          args.train_path,
          args.eval_path,
          args.max_n_samples,
          args.batch_size,
          args.epochs,
          args.learning_rate,
          args.optimizer,
          args.out_dir)